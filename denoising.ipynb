{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, show, figure\n",
    "from PIL import Image\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import RandomCrop, ToTensor, Compose, RandomHorizontalFlip, RandomVerticalFlip, ToPILImage\n",
    "from denoising_dataset import DenoisingDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage import color, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"data/train/\"\n",
    "VALIDATION_DATA_PATH = \"data/val/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, depth=7, n_channels=16, image_channels=3, use_bnorm=True, kernel_size=3):\n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        layers = []\n",
    "\n",
    "        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(depth-2):\n",
    "            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum = 0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dncnn(x)\n",
    "        return x - out\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the model, dataset, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DnCNN()\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m DenoisingDataset(TRAIN_DATA_PATH)   \u001b[38;5;66;03m#from denoising_datset.py file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "File \u001b[1;32m~\\denoising_dataset.py:11\u001b[0m, in \u001b[0;36mDenoisingDataset.__init__\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_path):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_images \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, filename))) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_path)]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25.0\u001b[39m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transforms \u001b[38;5;241m=\u001b[39m Compose([\n\u001b[0;32m     15\u001b[0m         ToPILImage(),\n\u001b[0;32m     16\u001b[0m         RandomCrop(\u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m     17\u001b[0m         RandomHorizontalFlip(),\n\u001b[0;32m     18\u001b[0m         RandomVerticalFlip(),\n\u001b[0;32m     19\u001b[0m         ToTensor()])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data/train/'"
     ]
    }
   ],
   "source": [
    "model = DnCNN()\n",
    "dataset = DenoisingDataset(TRAIN_DATA_PATH)   #from denoising_datset.py file\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DenoisingDataset(TRAIN_DATA_PATH)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_id in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0  # Initialize total loss for the epoch\n",
    "\n",
    "    for iter_id, (input_images, target_images) in enumerate(test_loader):\n",
    "        predicted_images = model(input_images)\n",
    "        loss = criterion(predicted_images, target_images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        print(\"\\rEpoch {} Iteration {} Loss {}\".format(epoch_id, iter_id, loss.item() / BATCH_SIZE), end=\"\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Convert tensors to numpy arrays\n",
    "            img_true = transforms.ToPILImage()(targets.squeeze(0))\n",
    "            img_pred = transforms.ToPILImage()(outputs.squeeze(0))\n",
    "\n",
    "            # Convert to grayscale if needed\n",
    "            img_true_gray = color.rgb2gray(img_true)\n",
    "            img_pred_gray = color.rgb2gray(img_pred)\n",
    "\n",
    "            psnr = metrics.peak_signal_noise_ratio(img_true_gray, img_pred_gray)\n",
    "            ssim = metrics.structural_similarity(img_true_gray, img_pred_gray, data_range=img_true_gray.max() - img_true_gray.min())\n",
    "\n",
    "\n",
    "            total_psnr += psnr\n",
    "            total_ssim += ssim\n",
    "\n",
    "    average_psnr = total_psnr / len(test_loader)\n",
    "    average_ssim = total_ssim / len(test_loader)\n",
    "\n",
    "    print(\"\\n Avg. PSNR: {:.2f}, Avg. SSIM: {:.4f}\".format(average_psnr, average_ssim))\n",
    "\n",
    "    # Learning rate scheduling\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Early stopping condition (you may need to customize this)\n",
    "    if epoch_id > 10 and total_loss / len(test_loader) < 0.001:\n",
    "        print(\"Early stopping as the loss is not improving.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.item() / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model with a Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, clear_output\n",
    "from matplotlib.pyplot import figure, imshow, show\n",
    "\n",
    "def visualize_validation(model):\n",
    "    model.eval()\n",
    "    image_path = os.path.join(VALIDATION_DATA_PATH, \"pier.png\")\n",
    "    original_image = Image.open(image_path)\n",
    "    original_image = np.array(original_image).astype(\"float32\") / 255.\n",
    "    model_input = torch.from_numpy(original_image).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = model(model_input)\n",
    "\n",
    "    result_image = result[0].clamp(0, 1).permute(1, 2, 0).numpy()\n",
    "    result_image = (result_image * 255).astype(\"uint8\")\n",
    "    \n",
    "    stacked_images = np.zeros((original_image.shape[0], original_image.shape[1] * 2, original_image.shape[2]), dtype=\"uint8\")\n",
    "    stacked_images[:, :original_image.shape[1]] = (original_image * 255).astype(\"uint8\")\n",
    "    stacked_images[:, original_image.shape[1]:] = result_image\n",
    "    \n",
    "    # Display images with labels\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(figsize=(28, 28))\n",
    "    ax.imshow(stacked_images)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_validation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
